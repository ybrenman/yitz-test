<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
    <head>
        <title>Pivotal Product Documentation : Data Source Management Guide</title>
        <link rel="stylesheet" href="styles/site.css" type="text/css" />
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>

    <body>
        <div id="page">
            <div id="main">
                <div id="main-header" class="pageSectionHeader">
                    <h1 id="title-heading" class="pagetitle">
                                                <span id="title-text">
                            Pivotal Product Documentation : Data Source Management Guide
                        </span>
                    </h1>

                    <div class="page-metadata">
                        <p>This page last changed on Oct 31, 2013 by <font color="#0050B2">rawlie</font>.</p>
                    </div>
                </div>

                <div id="content" class="view">
                    <div id="main-content" class="wiki-content group">
                    <p><style type='text/css'>/*<![CDATA[*/
div.rbtoc1384294742040 {padding: 0px;}
div.rbtoc1384294742040 ul {list-style: disc;margin-left: 0px;}
div.rbtoc1384294742040 li {margin-left: 0px;padding-left: 0px;}

/*]]>*/</style><div class='toc rbtoc1384294742040'>
<ul class='toc-indentation'>
<li><a href='#DataSourceManagementGuide-AboutDataSources'>About Data Sources</a>
<ul class='toc-indentation'>
<li><a href='#DataSourceManagementGuide-DataSourcesPage'>Data Sources Page</a></li>
<li><a href='#DataSourceManagementGuide-DataUploadFormats'>Data Upload Formats</a>
<ul class='toc-indentation'>
<li><a href='#DataSourceManagementGuide-Treatingfilecontentsassingle-lineevents'>Treating file contents as single-line events</a></li>
<li><a href='#DataSourceManagementGuide-AboutCompressedFiles'>About Compressed Files</a></li>
</ul>
</li>
<li><a href='#DataSourceManagementGuide-ExtractionandDataQualityRules'>Extraction and Data Quality Rules</a></li>
<li><a href='#DataSourceManagementGuide-UpdateRules'>Update Rules</a></li>
<li><a href='#DataSourceManagementGuide-SchedulingOptions'>Scheduling Options</a></li>
</ul>
</li>
<li><a href='#DataSourceManagementGuide-AddingDataSources'>Adding Data Sources</a>
<ul class='toc-indentation'>
<li><a href='#DataSourceManagementGuide-UploadFiles'>Upload Files</a></li>
<li><a href='#DataSourceManagementGuide-livefeedsLiveFeeds'><span class="confluence-anchor-link" id="DataSourceManagementGuide-livefeeds">Live Feeds</span></a></li>
<li><a href='#DataSourceManagementGuide-amazons3AmazonS3'><span class="confluence-anchor-link" id="DataSourceManagementGuide-amazons3">Amazon S3</span></a></li>
<li><a href='#DataSourceManagementGuide-hdfsHDFS'><span class="confluence-anchor-link" id="DataSourceManagementGuide-hdfs">HDFS</span></a></li>
<li><a href='#DataSourceManagementGuide-ftpFTP/SFTP'><span class="confluence-anchor-link" id="DataSourceManagementGuide-ftp">FTP/SFTP</span></a></li>
<li><a href='#DataSourceManagementGuide-nfsNFS'><s><span class="confluence-anchor-link" id="DataSourceManagementGuide-nfs">NFS</span></s></a></li>
<li><a href='#DataSourceManagementGuide-gemfireGemFire'><span class="confluence-anchor-link" id="DataSourceManagementGuide-gemfire">GemFire</span></a></li>
<li><a href='#DataSourceManagementGuide-ApplicationFeeds'><span>&nbsp;</span>Application Feeds&nbsp;</a></li>
</ul>
</li>
<li><a href='#DataSourceManagementGuide-DataIngestionAPIs'>Data Ingestion APIs</a></li>
<li><a href='#DataSourceManagementGuide-ResettingDataSources'>Resetting Data Sources</a></li>
</ul>
</div></p><h1 id="DataSourceManagementGuide-AboutDataSources" style="text-align: left;">About Data Sources</h1><p>Pivotal Analytics <em>Data Sources</em> define the set of data you want to analyze. You define one or more data sources for each Pivotal Analytics project. (For more information about Pivotal Analytics projects, see <a href="Administration%2BGuide.html#AdministrationGuide-manageprojects">Managing Projects</a>.)<span style="background-color: transparent;font-size: 14.0px;line-height: 1.4285715;"> Data sources can consist of static files from a variety of sources and it can include live data feeds from applications, log data, and other messages. The procedures for loading these various types of data are discussed in this chapter. Although you can likely work directly with existing data sources, your business requirements may require that the data be manipulated by filtering, normalizing or eliminating unneeded data dimensions before being submitted to the Pivotal Analytics system.</span></p><p><span style="background-color: transparent;font-size: 14.0px;line-height: 1.4285715;">When you submit a data source for processing, Pivotal Analytics analyzes and indexes the data using the configured Pivotal HD Hadoop cluster. Once this process is complete, you can begin to use Pivotal Analytics to visualize and analyze your data.   </span></p><p> </p><p><span style="background-color: transparent;font-size: 14.0px;line-height: 1.4285715;"> <span class="confluence-anchor-link" id="DataSourceManagementGuide-dataformats"></span> </span></p><h2 id="DataSourceManagementGuide-DataSourcesPage">Data Sources Page</h2><p>The Data Sources page is where you add and manage the data sources for your Pivotal Analytics project.</p><p>To view the Data Sources page:</p><ol><li>Login to Pivotal Analytics.</li><li>Select <strong>Data Sources</strong> from the left menu.</li></ol><p><img class="confluence-embedded-image confluence-thumbnail" width="150" src="attachments/thumbnails/62620469/64192523" data-image-src="attachments/62620469/64192523.png"></p><p>The <strong>Data Sources</strong> page displays an overview of the data sources configured for the current project. You can see at a glance, the number of events processed in the last day and detailed information on each data source you have configured. Click the <strong>Application Feeds</strong> tab to see information about your application feeds. </p><p><img class="confluence-embedded-image" width="700" src="attachments/62620469/64192524.png" data-image-src="attachments/62620469/64192524.png"></p><h2 id="DataSourceManagementGuide-DataUploadFormats">Data Upload Formats</h2><p>Depending on which type of data source you are processing, you can use one of the following data formats to add data sources:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th width="20%" class="confluenceTh">Data Format</th><th class="confluenceTh">Description</th></tr><tr><td class="confluenceTd">Autodetect</td><td class="confluenceTd">Automatically discovers the format of your data among all currently supported formats, or combinations of formats (including many not explicitly shown in the list ?? true?).</td></tr><tr><td class="confluenceTd">Apache CLF</td><td class="confluenceTd">Select this format for data compliant with the Apache Common Log Format, or the Apache Combined Log Format.</td></tr><tr><td colspan="1" class="confluenceTd"><p>Avro</p></td><td colspan="1" class="confluenceTd">Select this format for data generated by the Avro framework. Avro is a serialized data communication format used by Hadoop.</td></tr><tr><td class="confluenceTd">CSV (no header)<span class="confluence-anchor-link" id="DataSourceManagementGuide-csv"></span></td><td class="confluenceTd"><p>Select this format for data formatted as Comma Separated Values or, more generally, Delimiter Separated Values, where the &quot;delimiter&quot; can be any character frequently used as a separator (e.g., a comma or tab). When you select CSV, the following additional options display:</p><ul><li><span> <strong>Separator</strong>—select <strong>Autodetect</strong>, or you can select one of several options for field separators<br /> </span></li><li><span> <strong>Quotes</strong>—select the type of quotes used to identify strings in your data or select none. <br /> </span></li><li><span> <strong>Headers</strong>—You can use headers to define the field names in your data. Select the way headers are defined in your data from the following options: </span><ul><li><span> <strong>First row of file is header</strong>—select this option if your CSV file includes filed headers on the first line</span></li><li><span> <strong>System assigned header</strong>—select this option to allow Pivotal Analytics to automatically name the fields</span></li><li><span> <strong>User defined</strong>—the system prompts you for field names</span></li><li><span> <strong>External header file</strong>—the system prompts you for a CSV-formatted header file that defines the field name.</span></li></ul></li></ul><p><span>See <a href="Data%2BSource%2BManagement%2BGuide.html">Treating file contents as single-line events</a>.</span></p></td></tr><tr><td colspan="1" class="confluenceTd">Excel</td><td colspan="1" class="confluenceTd"><p>Select this format to upload files in Microsoft Excel format. The files should be basic spreadsheets that do not contain graphics and have a well-formed row and column structure that can be exported to the CSV format. The first row of the worksheet should contain field names for the columns.</p><p>You can upload an Excel workbook file that contains multiple spreadsheets. Each spreadsheet is processed as a separate file.</p></td></tr><tr><td colspan="1" class="confluenceTd">OpenTSDB</td><td colspan="1" class="confluenceTd">Select this format for time-series data that uses the OpenTSDB format of Hadoop Hbase.</td></tr><tr><td class="confluenceTd">Syslog (standard)</td><td class="confluenceTd">Select this format for data compliant with the Syslog format, as specified in RFC 3164.</td></tr><tr><td class="confluenceTd">Syslog (updated)</td><td class="confluenceTd">Select this format for data compliant with the updated Syslog format, as specified in RFC 5424.<br /> <br />?? only one syslog entry in dropdown.</td></tr><tr><td class="confluenceTd">Log4j</td><td class="confluenceTd"><p>Select this format for data compliant with the Apache Log4j format (using any of the many predefined patterns supported).</p></td></tr><tr><td class="confluenceTd">JSON</td><td class="confluenceTd"><p>Select this format for data compliant with the JavaScript Object Notation (JSON) format.</p><p><span>See </span><a href="Data%2BSource%2BManagement%2BGuide.html">Treating file contents as single-line events</a><span>.</span></p></td></tr><tr><td colspan="1" class="confluenceTd">TEXT</td><td colspan="1" class="confluenceTd"><p>Select this format for unstructured textual data.</p><p><span>See </span> <a href="Data%2BSource%2BManagement%2BGuide.html">Treating file contents as single-line events</a> <span>.</span></p></td></tr><tr><td colspan="1" class="confluenceTd">vShield</td><td colspan="1" class="confluenceTd">Select this format to upload log files from VMware vShield Servers.</td></tr><tr><td colspan="1" class="confluenceTd">XML</td><td colspan="1" class="confluenceTd">Select this format for XML-formatted data.</td></tr></tbody></table></div><p><span style="background-color: transparent;font-size: 14.0px;line-height: 1.4285715;">The data processing applied to your data source is driven by the Data Format you select. If you specify a data format for a file that is not compliant with that format, the data is still  processed, but with much less accuracy, depending on your actual selection.</span></p><p><span style="background-color: transparent;font-size: 14.0px;line-height: 1.4285715;"> <span class="confluence-anchor-link" id="DataSourceManagementGuide-multiline"></span> </span></p><h3 id="DataSourceManagementGuide-Treatingfilecontentsassingle-lineevents">Treating file contents as single-line events</h3><p>For the CSV, JSON, and TEXT data sources, de-select the <strong>Treat file contents as single-line events</strong>  if your data spans multiple lines. </p><p>When checked, input files processed using MapReduce inside Hadoop are initially split into multiple sub-files and each sub-file is processed independently for parallelization.  <span>The splits occur using a newline as the event/record boundary. Although this is correct in most formats such as CSV and single-line JSON, this will not be correct in cases where events/records span across multiple lines.</span></p><h3 id="DataSourceManagementGuide-AboutCompressedFiles">About Compressed Files</h3><p>You can upload your files as uncompressed plain text, or as compressed data in any of the following formats (or their common combinations):</p><ul><li><code>BZIP2</code> (<code>bz2</code>)</li><li><code>GZIP</code> (<code>gz</code>)</li><li><code>JAR</code></li><li><code>LZO</code></li><li><code>ZIP</code></li><li><code>TAR</code></li><li>GZipped <code>TAR</code> (<code>.tar.gz</code>)</li></ul><p>Note the following regarding compression:</p><ul><li>To upload compressed archives containing files in different formats (any of the supported formats, as listed above), use the <strong>Autodetect</strong> option.</li><li>If you select any a data format (any available option other than <strong>Autodetect</strong>), all the files in the compressed archive are processed as compliant with that format.</li><li>The compression format of each file is automatically detected according to the file's contents, therefore you can use any file name or extension.</li></ul><p>?? keep this?? If the data or compression format of your file is not identified by the &quot;Autodetect&quot; option, or is not explicitly listed above, or for any other related issue, please contact us at <a href="https://mail.google.com/a/gopivotal.com/mail/?view=cm&amp;fs=1&amp;tf=1&amp;to=support@cetas.net" class="external-link" rel="nofollow">support@cetas.net</a> for further options.</p><p><span class="confluence-anchor-link" id="DataSourceManagementGuide-extraction"></span></p><h2 id="DataSourceManagementGuide-ExtractionandDataQualityRules">Extraction and Data Quality Rules</h2><p>When prompted, choose one of the following Extraction and Data Quality Rules:</p><ul><li style="text-align: left;"><strong>Retain raw event</strong>—In addition to normal processing, raw events are also retained &quot;as is&quot; (only useful if you plan to do searches on original events).</li><li><strong>Enable Data Quality Control</strong>—You can include or exclude events using a regular expression. When you select this option, two text boxes display where you can enter text to either drop or accept events that match the expression. Select the the radio button to Accept or Drop events.  </li><li><strong>Field Extraction Rules</strong>—You can extract data from a data set into a new file using a regular expression. Enter values for the name of the field and the expression and click <strong>Add Rule</strong>. You can add multiple rules.</li></ul><p><span> <span class="confluence-anchor-link" id="DataSourceManagementGuide-updaterules"></span> </span></p><h2 id="DataSourceManagementGuide-UpdateRules">Update Rules</h2><p><span>When prompted, select one of the following Update Rules:</span></p><ul><li><strong>Regular</strong>—New data is added to the end of the existing data and does not update or replace previously loaded data. If the data source name exactly matches the name of a previously loaded data source, all data is replaced with the new data. </li><li><strong>Update</strong>—If the keys match, the old data is updated with the new data in the upload. A text box display where you can define one or more key fields. Click <strong>Add another key</strong> to enter a additional keys. Click the minus sign to remove a key. </li></ul><p><span class="confluence-anchor-link" id="DataSourceManagementGuide-scheduling"></span></p><h2 id="DataSourceManagementGuide-SchedulingOptions">Scheduling Options</h2><p>The following options are available when scheduling data sources:</p><ul><li><strong>Run-immediately</strong>—upload the file now, and do not repeat the upload</li><li><strong>Hourly</strong>—upload the file every hour or at an interval of hours that you specify. A set of fields display to schedule when and how often the upload occurs. You can also specify a start and end date.  </li><li><strong>Daily</strong>—upload the file every day or at an interval of days that you specify. A set of fields display to schedule when and how often the upload occurs. You can also specify a start and end date.  </li><li><strong>Weekly</strong>—upload the file every week or specify an interval of weeks. You can also specify the day of the week when the upload occurs. A set of fields display to schedule when and how often the upload occurs. You can also specify a start and end date.  </li><li><strong>Monthly</strong>—upload the file every month or at an interval of months that you specify. A set of fields display to schedule when and how often the upload occurs. You can also specify a start and end date.  </li></ul><h1 id="DataSourceManagementGuide-AddingDataSources">Adding Data Sources</h1><p><span style="background-color: transparent;font-size: 14.0px;line-height: 1.4285715;">To begin adding data sources:</span></p><ol><li><p>Login to Pivotal Analytics<span style="font-size: 14.0px;line-height: 1.4285715;"> and click </span><strong style="font-size: 14.0px;line-height: 1.4285715;">Data Sources</strong><span style="font-size: 14.0px;line-height: 1.4285715;"> in the left menu.</span><br /><span style="background-color: transparent;font-size: 14.0px;line-height: 1.4285715;">The Add Data Sources menu displays:</span></p><p><img class="confluence-embedded-image" src="attachments/62620469/64192568.png" data-image-src="attachments/62620469/64192568.png"></p></li><li>Follow the procedures below to add any of the following data sources:<ul><li><a href="Data%2BSource%2BManagement%2BGuide.html">Upload Files</a></li><li><a href="Data%2BSource%2BManagement%2BGuide.html">Live Feeds</a></li><li><a href="Data%2BSource%2BManagement%2BGuide.html">Amazon S3</a></li><li><a href="Data%2BSource%2BManagement%2BGuide.html">HDFS</a></li><li><a href="Data%2BSource%2BManagement%2BGuide.html">FTP/SFTP</a></li><li><a href="Data%2BSource%2BManagement%2BGuide.html">GemFire</a></li><li><a href="Data%2BSource%2BManagement%2BGuide.html">Application Feed</a></li></ul></li></ol><p><span class="confluence-anchor-link" id="DataSourceManagementGuide-uploadfiles"></span></p><h2 id="DataSourceManagementGuide-UploadFiles">Upload Files</h2><p>The Upload Files data source allows you to  directly upload files from your local machine. </p><p>To upload files:</p><ol><li>Login to Pivotal Analytics.</li><li>Select <strong>Data Sources</strong> from the left menu.</li><li>Click <strong>Upload File</strong> from the <strong>Add Data Sources</strong> menu.</li><li>Select the <strong>Add Source</strong> tab</li><li>Drag and drop one or more files into the grey box or click <strong>Choose Files</strong> to open a file browser.<br />The file uploads to Pivotal Analytics and displays a progress meter. When the upload is complete you will see a green checkmark icon and the file uploaded message.</li><li>After the files upload, click <strong>Next.</strong></li><li>Select a data format and type, or select <strong>Autodetect</strong>.<strong> </strong>You can choose any of the data formats listed in the <a href="Data%2BSource%2BManagement%2BGuide.html">Data Upload Formats</a> table. </li><li><span style="font-size: 14.0px;line-height: 1.4285715;">Click </span> <strong style="font-size: 14.0px;line-height: 1.4285715;">Next.</strong></li><li><span style="font-size: 14.0px;line-height: 1.4285715;">(Optional) Select an Extraction and Data Quality Rules option <br />See <a href="Data%2BSource%2BManagement%2BGuide.html">Extraction and Data Quality Rules</a>.</span></li><li>Click <strong>Next</strong>.</li><li><span style="font-size: 14.0px;line-height: 1.4285715;">Select an Update Rule.<br /> See <a href="Data%2BSource%2BManagement%2BGuide.html">Update Rules</a>.</span> <span style="font-size: 14.0px;line-height: 1.4285715;"> </span></li><li>(Optional) Click <strong>Preview</strong> to view the data set you are loading.</li><li>Click <strong>Done</strong>. <br />The data uploads and processing begins. You can view the status of your uploads on the <strong>Data Feeds tab</strong>. <br /><img class="confluence-embedded-image" width="700" src="attachments/62620469/64192525.png" data-image-src="attachments/62620469/64192525.png"> <br />Click <strong>Details</strong> for additional status information.  <br />Click the <strong>Trash</strong> icon to delete the data source.<br />Click  the red <strong>Stop</strong> icon to stop processing the data.<br /> <br />When the processing of the uploaded file is complete, a notification displays. </li></ol><h2 id="DataSourceManagementGuide-livefeedsLiveFeeds"><span class="confluence-anchor-link" id="DataSourceManagementGuide-livefeeds"></span>Live Feeds</h2><p>The Live Feeds data source option allows you to stream data from log files in formats such as log4j or JSON.</p><p>To add a Live Feed data source:</p><ol><li>Login to Pivotal Analytics.</li><li>Select <strong>Data Sources</strong> from the left menu.</li><li>Select <strong>Live Feeds</strong> from the <strong>Add Data Sources</strong> menu.</li><li>Enter a name for the data source in the <strong>Source Name</strong> field.</li><li><span>(Optional) Select an Extraction and Data Quality Rules option <br />See <a href="Data%2BSource%2BManagement%2BGuide.html">Extraction and Data Quality Rules</a>.</span></li><li>Click <strong>Next</strong>.</li><li><span>Select an Update Rule.<br />See <a href="Data%2BSource%2BManagement%2BGuide.html">Update Rules</a>.</span> <span> </span></li><li><span style="font-size: 14.0px;line-height: 1.4285715;">(Optional) Click </span> <strong style="font-size: 14.0px;line-height: 1.4285715;">Preview</strong> <span style="font-size: 14.0px;line-height: 1.4285715;"> to view the data set you are loading.</span></li><li>Click <strong>Done</strong>.</li></ol><h2 id="DataSourceManagementGuide-amazons3AmazonS3"><span class="confluence-anchor-link" id="DataSourceManagementGuide-amazons3"></span>Amazon S3</h2><p>You can add data sources that are stored in Amazon S3 cloud storage service. Before configuring an S3 data source, you must obtain the following information from your S3 environment:</p><ul><li>Access Key</li><li>Secret Key</li><li>S3 Root URL</li></ul><p>To add an Amazon S3 data source:</p><ol><li>Login to Pivotal Analytics.</li><li>Select <strong>Data Sources</strong> from the left menu.</li><li>Select <strong>Amazon S3</strong> from the <strong>Add Data Sources</strong> menu.</li><li>Enter your Access Key, Secret Key</li><li>Enter your S3 URL or click browse to locate the URL.</li><li>Click <strong>Next</strong>.</li><li>Select a data format from the drop-down list or select <strong>Autodetect</strong>. See <a href="Data%2BSource%2BManagement%2BGuide.html">Data Upload Formats</a>.</li><li><span>(Optional) Select an Extraction and Data Quality Rules option <br />See <a href="Data%2BSource%2BManagement%2BGuide.html">Extraction and Data Quality Rules</a>.</span></li><li>Click <strong>Next</strong>.</li><li><span>Select an Update Rule.<br />See <a href="Data%2BSource%2BManagement%2BGuide.html">Update Rules</a>.</span> <span> </span></li><li><span style="font-size: 14.0px;line-height: 1.4285715;">(Optional) Click </span> <strong style="font-size: 14.0px;line-height: 1.4285715;">Preview</strong> <span style="font-size: 14.0px;line-height: 1.4285715;"> to view the data set you are loading.</span></li><li>Click <strong>Next.</strong></li><li>In the <strong>Repeats</strong> drop-down list, select a schedule option. Your file will upload automatically using the schedule you specify. See <a href="Data%2BSource%2BManagement%2BGuide.html">Scheduling Options</a>.<span style="font-size: 14.0px;line-height: 1.4285715;"> </span></li><li>If you selected a scheduling option other than Run-immediately, select <strong>Incremental Processing</strong> to load only new data. </li><li>Click <strong>Done</strong>. <br />The data uploads and processing begins. You can view the status of your uploads on the <strong>Data Feeds tab</strong>. </li></ol><h2 id="DataSourceManagementGuide-hdfsHDFS"><span class="confluence-anchor-link" id="DataSourceManagementGuide-hdfs"></span>HDFS</h2><p>To add data stored in a Hadoop File system:</p><ol><li>Login to Pivotal Analytics.</li><li>Select <strong>Data Sources</strong> from the left menu.</li><li>Select <strong>HDFS</strong> from the <strong>Add Data Sources</strong> menu.</li><li>Select the type of Hadoop distribution where your data is stored. Chose one of the following options:<ul><li>Pivotal Hadoop Distribution 1.0</li><li>Cloudera Distribution for Hadoop 3</li><li>Cloudera Distribution for Hadoop 4</li></ul></li><li>Enter the HDFS root URL. </li><li>Select the <strong>Hadoop Processing</strong> option to process the data on the Hadoop cluster where the data source resides. If you do not select this option, processing occurs only on Pivotal Analytic nodes, which may reduce performance.</li><li>Select the <strong>Auto Summarize</strong> option to ?? <span style="color: rgb(153,153,149);">Individual events will not be indexed, but the resulting metadata size will be much smaller.</span> <br /> <span style="color: rgb(153,153,149);">If not checked, individual events will be indexed and will require provisioning of sufficient storage for metadata.</span></li><li>Select a data format from the drop-down list or select <strong>Autodetect</strong>. See <a href="Data%2BSource%2BManagement%2BGuide.html">Data Upload Formats</a>.</li><li><span>?? the <strong>Treat file contents as single-line events</strong> option is available. De-select this option if your data spans multiple lines. ??is that right?</span></li><li><span>(Optional) Select an Extraction and Data Quality Rules option <br />See <a href="Data%2BSource%2BManagement%2BGuide.html">Extraction and Data Quality Rules</a>.</span></li><li>Click <strong>Next</strong>.</li><li><span>Select an Update Rule.<br />See <a href="Data%2BSource%2BManagement%2BGuide.html">Update Rules</a>.</span> <span> </span></li><li><span style="font-size: 14.0px;line-height: 1.4285715;">In the </span> <strong style="font-size: 14.0px;line-height: 1.4285715;">Repeats</strong> <span style="font-size: 14.0px;line-height: 1.4285715;"> drop-down list, select a schedule option. Your file will upload automatically using the schedule you specify. See </span> <a href="Data%2BSource%2BManagement%2BGuide.html">Scheduling Options</a> <span style="font-size: 14.0px;line-height: 1.4285715;">.</span></li><li><span>Click <strong>Done</strong>. </span></li></ol><h2 id="DataSourceManagementGuide-ftpFTP/SFTP"><span class="confluence-anchor-link" id="DataSourceManagementGuide-ftp"></span>FTP/SFTP</h2><p>To upload data from files stored on FTP or SFTP sources:</p><ol><li>Login to Pivotal Analytics.</li><li>Select <strong>Data Sources</strong> from the left menu.</li><li>Select <strong>FTP/SFTP</strong> from the <strong>Add Data Sources</strong> menu.</li><li>Select the type of file transport from the <strong>FTP/SFTP</strong> drop-down list, either FTP or SFTP.</li><li>Enter the <strong>Username</strong> for access to the FTP or SFTP account.</li><li>Enter the <strong>Password</strong> for access to the FTP or SFTP account.</li><li>Enter the FTP Root directory URL or click the <strong>Browse</strong> button to browse to the directory. </li><li>Select a data format from the drop-down list or select <strong>Autodetect</strong>. See <a href="Data%2BSource%2BManagement%2BGuide.html">Data Upload Formats</a>.</li><li><span>(Optional) Select an Extraction and Data Quality Rules option <br />See <a href="Data%2BSource%2BManagement%2BGuide.html">Extraction and Data Quality Rules</a>.</span></li><li>Click <strong>Next</strong>.</li><li><span>Select an Update Rule.<br />See <a href="Data%2BSource%2BManagement%2BGuide.html">Update Rules</a>.</span> <span> </span></li><li><span style="font-size: 14.0px;line-height: 1.4285715;">In the </span> <strong style="font-size: 14.0px;line-height: 1.4285715;">Repeats</strong> <span style="font-size: 14.0px;line-height: 1.4285715;"> drop-down list, select a schedule option. Your file will upload automatically using the schedule you specify. See </span> <a href="Data%2BSource%2BManagement%2BGuide.html">Scheduling Options</a> <span style="font-size: 14.0px;line-height: 1.4285715;">.</span></li></ol><h2 id="DataSourceManagementGuide-nfsNFS"><s><span class="confluence-anchor-link" id="DataSourceManagementGuide-nfs"></span>NFS</s></h2><p><s>To upload data files stored on NFS sources:</s></p><ol><li><s>Login to Pivotal Analytics.</s></li><li><s>Select <strong>Data Sources</strong> from the left menu.</s></li><li><s>Select <strong>NFS Source</strong> from the <strong>Add Data Sources</strong> menu.</s></li><li><s><span style="font-size: 14.0px;line-height: 1.4285715;">Enter the </span> <strong style="font-size: 14.0px;line-height: 1.4285715;">Password</strong> <span style="font-size: 14.0px;line-height: 1.4285715;"> for access to the FTP or SFTP account.</span></s></li><li><s>Enter the NFS Root directory URL or click the <strong>Browse</strong> button to browse to the directory. </s></li><li><s>Select a data format from the drop-down list or select <strong>Autodetect</strong>. See <a href="Data%2BSource%2BManagement%2BGuide.html">Data Upload Formats</a>.</s></li><li><s><span>(Optional) Select an Extraction and Data Quality Rules option <br />See <a href="Data%2BSource%2BManagement%2BGuide.html">Extraction and Data Quality Rules</a>.</span></s></li><li><s>Click <strong>Next</strong>.</s></li><li><s><span>Select an Update Rule.<br />See <a href="Data%2BSource%2BManagement%2BGuide.html">Update Rules</a>.</span> <span> </span></s></li><li><s><span style="font-size: 14.0px;line-height: 1.4285715;">In the </span> <strong style="font-size: 14.0px;line-height: 1.4285715;">Repeats</strong> <span style="font-size: 14.0px;line-height: 1.4285715;"> drop-down list, select a schedule option. Your file will upload automatically using the schedule you specify. See </span> <a href="Data%2BSource%2BManagement%2BGuide.html">Scheduling Options</a> <span style="font-size: 14.0px;line-height: 1.4285715;">.</span></s></li></ol><h2 id="DataSourceManagementGuide-gemfireGemFire"><span class="confluence-anchor-link" id="DataSourceManagementGuide-gemfire"></span>GemFire</h2><p>You can add a data sources that retrieves data from a (Pivotal vFabric??) GemFire region. Consult the GemFire documentation for more information about data access in GemFire.</p><ol><li>Login to Pivotal Analytics.</li><li>Select <strong>Data Sources</strong> from the left menu.</li><li>Select <strong>GemFire Source</strong> from the <strong>Add Data Sources</strong> menu.</li><li>Enter a name for the source (for internal reference only) in the <strong>Source Name</strong> field. </li><li>Enter the host name of the GemFire installation in the <strong>GemFire Server Host</strong> field.</li><li>Enter the port number of the GemFire installation in the <strong>GemFire Server Port</strong> field.</li><li>Select the type of query from the following options:<ul><li><strong>Continuous Query</strong>—Enter a query string for a GemFire continuous query.</li><li><strong>One Time Query</strong>—Enter a query string for a query that is performed immediately. </li><li><strong>Register for Events by regular expression</strong>—Enter a <strong>Region Name</strong> and a <strong>Regular Expression</strong> </li></ul></li><li><span style="font-size: 14.0px;line-height: 1.4285715;">In the </span> <strong style="font-size: 14.0px;line-height: 1.4285715;">Repeats</strong> <span style="font-size: 14.0px;line-height: 1.4285715;"> drop-down list, select a schedule option. Your file will upload automatically using the schedule you specify. See </span> <a href="Data%2BSource%2BManagement%2BGuide.html">Scheduling Options</a> <span style="font-size: 14.0px;line-height: 1.4285715;">.</span></li><li>Click <strong>Done</strong>.</li></ol><p><span class="confluence-anchor-link" id="DataSourceManagementGuide-applicationfeed"></span></p><h2 id="DataSourceManagementGuide-ApplicationFeeds"><span> </span>Application Feeds </h2><p>You can add data from running applications by coding those applications to send event messages to Pivotal Analytics. You define a data source in Pivotal Analytics and the system provides you with snippets of application code you can embed in your applications to send the event messages. Code is available for the following environments:</p><p> </p><ul><li>JavaScript API—Use the Pivotal Analytics JavaScript API to write code that tracks the data you want to analyze.</li><li>JavaScript Page Visit event—Use this option to track page views. Event data includes URLs visited, Page Title, Session Analysis, screen resolution, browser, and operating system information.  </li><li>JavaScript Page DOM Click Event—Use this option to track mouse click events. </li><li>JavaScript eCommerce Event—Use this option to track ecommerce activities. Event data includes shopping carts, products, and custom variables. </li><li>JavaScript Game tracking event—Use this option to track user activites while playing a game, for example, advancing levels, invitations to friends, and purchasing of virtual goods.</li><li>JavaScript User action event—Use this option to track user actions on a site. </li><li>JavaScript Custom event—Use this option to track custom events that you define. </li><li>REST API—You can write custom code using a REST API to send application events to Pivotal Analytics. </li></ul><p>To configure an Application Feed:</p><ol><li>Login to Pivotal Analytics.</li><li>Select <strong>Data Sources</strong> from the left menu.</li><li>Select <strong>Application Feed</strong> from the <strong>Add Data Sources</strong> menu.</li><li>Enter a name for the application feed in the <strong>Application Name</strong> field.</li><li>Enter the URL of the application in the <strong>URL</strong> field.</li><li>(Optional) Enter a description of the application in the <strong>Description</strong> field.</li><li>Select the type of application. (?? WHAT ARE IMPLICATIONS OF EACH? )You can choose from:<ul><li>WEB</li><li>MOBILE</li><li>FACEBOOK</li><li>DESKTOP</li><li>UNKNOWN</li></ul></li><li>Click <strong>Next</strong>.</li><li>Select an Update Rule.<br />See <a href="Data%2BSource%2BManagement%2BGuide.html">Update Rules</a>.  </li><li>Click <strong>Done</strong>.<br />The Application Details screen displays. </li><li>Select the JavaScript tab and and event type to copy application tracking code for any of the listed events. You can paste this code into your application. Select the REST API tab for information about adding Web services code using the REST API. You can also access the API key from this page. </li><li>(Optional) Click <strong>Preview</strong> to preview the data from the application feed. ??really?</li></ol><h1 id="DataSourceManagementGuide-DataIngestionAPIs">Data Ingestion APIs</h1><p>The Data Ingestion APIs are provided in the form of either a set of SDKs for various languages or RESTful APIs for integration of any client that can follow the RESTful API model. A summary of the APIs that can be used for ingestion are listed below (click on the corresponding link for more information):</p><ul><li><a href="JavaScript%2BData%2BIngest%2BSDK.html">JavaScript Data Ingest SDK</a></li><li><a href="Data%252BIngestion%252BRESTful%252BAPIs.html">Data+Ingestion+RESTful+APIs</a></li><li><a href="Data%252BIngestion%252BSDK%252B%2528Java%2529.html">Data+Ingestion+SDK+(Java)</a></li></ul><h1 id="DataSourceManagementGuide-ResettingDataSources">Resetting Data Sources</h1><p>You can reset all data sources so that the indexes are cleaned up. </p><p>To reset data sources:</p><ol><li>Login to Pivotal Analytics.</li><li>Select <strong>Data Sources</strong> from the left menu.</li><li>Click the <strong>Reset All Data Sources</strong> link.</li></ol>
                    </div>

                                        <div class="pageSection group">
                        <div class="pageSectionHeader">
                            <h2 id="attachments" class="pageSectionTitle">Attachments:</h2>
                        </div>

                        <div class="greybox" align="left">
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/62620469/62783648.png">image2013-10-3 15:32:52.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/62620469/62783649.png">image2013-10-3 16:38:58.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/62620469/62783650.png">image2013-10-3 16:40:11.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/62620469/63602689.png">go.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/62620469/63602701.png">image2013-10-7 13:21:40.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/62620469/63602702.png">image2013-10-7 13:23:19.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/62620469/63602703.png">image2013-10-7 13:41:2.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/62620469/64192523.png">data_sources_left_menu.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/62620469/64192524.png">data_sources_overview.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/62620469/64192525.png">direct_uploads.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/62620469/64192568.png">add_data_sources.png</a> (image/png)
                                <br/>
                                                    </div>
                    </div>
                    
                 
                </div>             </div> 
            <div id="footer" style="background: url(https://confluence.greenplum.com/images/border/border_bottom.gif) repeat-x;">
                <p><small>Document generated by Confluence on Nov 12, 2013 14:19</small></p>
            </div>
        </div>     </body>
</html>
